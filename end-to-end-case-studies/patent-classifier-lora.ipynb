{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install -q datasets==2.20.0 \\\n",
    "                 accelerate==0.33.0 \\\n",
    "                 evaluate==0.4.2 \\\n",
    "                 peft==0.12.0 \\\n",
    "                 adapters==1.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-29 09:42:36.085646: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-29 09:42:36.085715: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-29 09:42:36.086825: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-29 09:42:36.093182: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-29 09:42:36.996886: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import evaluate\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from adapters import AutoAdapterModel, AdapterTrainer, LoRAConfig\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method\n",
    "\n",
    "We use the HuggingFace Trainer library to conduct finetuning using PEFT adapters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"ccdv/patent-classification\", \"abstract\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d676a2e5f54149489d104c2ec8fb6266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = ds.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {\n",
    "    0: \"Human Necessities\", \n",
    "    1: \"Performing Operations; Transporting\",\n",
    "    2: \"Chemistry; Metallurgy\",\n",
    "    3: \"Textiles; Paper\",\n",
    "    4: \"Fixed Constructions\",\n",
    "    5: \"Mechanical Engineering; Lightning; Heating; Weapons; Blasting\",\n",
    "    6: \"Physics\",\n",
    "    7: \"Electricity\",\n",
    "    8: \"General tagging of new or cross-sectional technology\"\n",
    "}\n",
    "\n",
    "label2id = { v: k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoAdapterModel.from_pretrained(\"distilbert/distilbert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertAdapterModel(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlockWithAdapters(\n",
       "          (attention): MultiHeadSelfAttentionWithAdapters(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): LoRALinearTorch(\n",
       "              in_features=768, out_features=768, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (k_lin): LoRALinearTorch(\n",
       "              in_features=768, out_features=768, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (v_lin): LoRALinearTorch(\n",
       "              in_features=768, out_features=768, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (prefix_tuning): PrefixTuningLayer(\n",
       "              (prefix_gates): ModuleDict()\n",
       "              (pool): PrefixTuningPool(\n",
       "                (prefix_tunings): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): LoRALinearTorch(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (lin2): LoRALinearTorch(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (attention_adapters): BottleneckLayer(\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "          (output_adapters): BottleneckLayer(\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "          (reft_layer): ReftLayer(\n",
       "            (refts): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (invertible_adapters): ModuleDict()\n",
       "    (shared_parameters): ModuleDict()\n",
       "    (prefix_tuning): PrefixTuningPool(\n",
       "      (prefix_tunings): ModuleDict()\n",
       "    )\n",
       "    (prompt_tuning): PromptTuningLayer(\n",
       "      (base_model_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (prompt_tunings): ModuleDict()\n",
       "    )\n",
       "  )\n",
       "  (heads): ModuleDict(\n",
       "    (default): BertStyleMaskedLMHead(\n",
       "      (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (1): Activation_Function_Class(\n",
       "        (f): GELUActivation()\n",
       "      )\n",
       "      (2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (3): Linear(in_features=768, out_features=28996, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_classification_head('patent', num_labels=9, id2label=id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertAdapterModel(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlockWithAdapters(\n",
       "          (attention): MultiHeadSelfAttentionWithAdapters(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): LoRALinearTorch(\n",
       "              in_features=768, out_features=768, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (k_lin): LoRALinearTorch(\n",
       "              in_features=768, out_features=768, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (v_lin): LoRALinearTorch(\n",
       "              in_features=768, out_features=768, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (prefix_tuning): PrefixTuningLayer(\n",
       "              (prefix_gates): ModuleDict()\n",
       "              (pool): PrefixTuningPool(\n",
       "                (prefix_tunings): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): LoRALinearTorch(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (lin2): LoRALinearTorch(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (attention_adapters): BottleneckLayer(\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "          (output_adapters): BottleneckLayer(\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "          (reft_layer): ReftLayer(\n",
       "            (refts): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (invertible_adapters): ModuleDict()\n",
       "    (shared_parameters): ModuleDict()\n",
       "    (prefix_tuning): PrefixTuningPool(\n",
       "      (prefix_tunings): ModuleDict()\n",
       "    )\n",
       "    (prompt_tuning): PromptTuningLayer(\n",
       "      (base_model_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (prompt_tunings): ModuleDict()\n",
       "    )\n",
       "  )\n",
       "  (heads): ModuleDict(\n",
       "    (default): BertStyleMaskedLMHead(\n",
       "      (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (1): Activation_Function_Class(\n",
       "        (f): GELUActivation()\n",
       "      )\n",
       "      (2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (3): Linear(in_features=768, out_features=28996, bias=True)\n",
       "    )\n",
       "    (patent): ClassificationHead(\n",
       "      (0): Dropout(p=0.2, inplace=False)\n",
       "      (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (2): Activation_Function_Class(\n",
       "        (f): Tanh()\n",
       "      )\n",
       "      (3): Dropout(p=0.2, inplace=False)\n",
       "      (4): Linear(in_features=768, out_features=9, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoRAConfig(r=8, alpha=16)\n",
    "model.add_adapter(\"patent\", config=lora_config)\n",
    "model.set_active_adapters(\"patent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertAdapterModel(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlockWithAdapters(\n",
       "          (attention): MultiHeadSelfAttentionWithAdapters(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): LoRALinearTorch(\n",
       "              in_features=768, out_features=768, bias=True\n",
       "              (loras): ModuleDict(\n",
       "                (patent): LoRA()\n",
       "              )\n",
       "            )\n",
       "            (k_lin): LoRALinearTorch(\n",
       "              in_features=768, out_features=768, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (v_lin): LoRALinearTorch(\n",
       "              in_features=768, out_features=768, bias=True\n",
       "              (loras): ModuleDict(\n",
       "                (patent): LoRA()\n",
       "              )\n",
       "            )\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (prefix_tuning): PrefixTuningLayer(\n",
       "              (prefix_gates): ModuleDict()\n",
       "              (pool): PrefixTuningPool(\n",
       "                (prefix_tunings): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): LoRALinearTorch(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (lin2): LoRALinearTorch(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (attention_adapters): BottleneckLayer(\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "          (output_adapters): BottleneckLayer(\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "          (reft_layer): ReftLayer(\n",
       "            (refts): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (invertible_adapters): ModuleDict()\n",
       "    (shared_parameters): ModuleDict()\n",
       "    (prefix_tuning): PrefixTuningPool(\n",
       "      (prefix_tunings): ModuleDict()\n",
       "    )\n",
       "    (prompt_tuning): PromptTuningLayer(\n",
       "      (base_model_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (prompt_tunings): ModuleDict()\n",
       "    )\n",
       "  )\n",
       "  (heads): ModuleDict(\n",
       "    (default): BertStyleMaskedLMHead(\n",
       "      (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (1): Activation_Function_Class(\n",
       "        (f): GELUActivation()\n",
       "      )\n",
       "      (2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (3): Linear(in_features=768, out_features=28996, bias=True)\n",
       "    )\n",
       "    (patent): ClassificationHead(\n",
       "      (0): Dropout(p=0.2, inplace=False)\n",
       "      (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (2): Activation_Function_Class(\n",
       "        (f): Tanh()\n",
       "      )\n",
       "      (3): Dropout(p=0.2, inplace=False)\n",
       "      (4): Linear(in_features=768, out_features=9, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train_adapter('patent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertAdapterModel(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlockWithAdapters(\n",
       "          (attention): MultiHeadSelfAttentionWithAdapters(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): LoRALinearTorch(\n",
       "              in_features=768, out_features=768, bias=True\n",
       "              (loras): ModuleDict(\n",
       "                (patent): LoRA()\n",
       "              )\n",
       "            )\n",
       "            (k_lin): LoRALinearTorch(\n",
       "              in_features=768, out_features=768, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (v_lin): LoRALinearTorch(\n",
       "              in_features=768, out_features=768, bias=True\n",
       "              (loras): ModuleDict(\n",
       "                (patent): LoRA()\n",
       "              )\n",
       "            )\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (prefix_tuning): PrefixTuningLayer(\n",
       "              (prefix_gates): ModuleDict()\n",
       "              (pool): PrefixTuningPool(\n",
       "                (prefix_tunings): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): LoRALinearTorch(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (lin2): LoRALinearTorch(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (attention_adapters): BottleneckLayer(\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "          (output_adapters): BottleneckLayer(\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "          (reft_layer): ReftLayer(\n",
       "            (refts): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (invertible_adapters): ModuleDict()\n",
       "    (shared_parameters): ModuleDict()\n",
       "    (prefix_tuning): PrefixTuningPool(\n",
       "      (prefix_tunings): ModuleDict()\n",
       "    )\n",
       "    (prompt_tuning): PromptTuningLayer(\n",
       "      (base_model_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (prompt_tunings): ModuleDict()\n",
       "    )\n",
       "  )\n",
       "  (heads): ModuleDict(\n",
       "    (default): BertStyleMaskedLMHead(\n",
       "      (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (1): Activation_Function_Class(\n",
       "        (f): GELUActivation()\n",
       "      )\n",
       "      (2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (3): Linear(in_features=768, out_features=28996, bias=True)\n",
       "    )\n",
       "    (patent): ClassificationHead(\n",
       "      (0): Dropout(p=0.2, inplace=False)\n",
       "      (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (2): Activation_Function_Class(\n",
       "        (f): Tanh()\n",
       "      )\n",
       "      (3): Dropout(p=0.2, inplace=False)\n",
       "      (4): Linear(in_features=768, out_features=9, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Name                     Architecture         #Param      %Param  Active   Train\n",
      "--------------------------------------------------------------------------------\n",
      "patent                   lora                147,456       0.226       1       1\n",
      "--------------------------------------------------------------------------------\n",
      "Full model                                65,190,912     100.000               0\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(model.adapter_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"distilbert-patent\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=50,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = AdapterTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['validation'],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-29 09:43:42,623] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10827' max='78150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10827/78150 26:34 < 2:45:18, 6.79 it/s, Epoch 6.93/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.223700</td>\n",
       "      <td>1.165578</td>\n",
       "      <td>0.585200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.147500</td>\n",
       "      <td>1.105873</td>\n",
       "      <td>0.607800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.102900</td>\n",
       "      <td>1.071191</td>\n",
       "      <td>0.624200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.087900</td>\n",
       "      <td>1.051021</td>\n",
       "      <td>0.635000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.046000</td>\n",
       "      <td>1.042637</td>\n",
       "      <td>0.641200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.041100</td>\n",
       "      <td>1.033411</td>\n",
       "      <td>0.643000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'https://nlyin6uyku.clg07azjl.paperspacegradient.com/'. Verify the server is running and reachable."
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate(tokenized_dataset['test'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
